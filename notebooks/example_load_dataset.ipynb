{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Example usage of the Environment class to load custom (static) datasets.\n",
    "\n",
    "This notebook illustrates the example usage of the Environment class for loading custom (static) datasets from .csv files. It supports both observational and interventional data."
   ],
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "from src.config import EnvironmentConfig\n",
    "from src.environments.environment import Environment\n",
    "from src.environments.generic_environments import ErdosRenyi\n",
    "from src.utils.graphs import graph_from_csv\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "First, we generate a ground truth environment/SCM to generate some dummy data.\n",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# init environment\n",
    "env_cfg = EnvironmentConfig()\n",
    "env_cfg.generate_static_obs_dataset = True\n",
    "env_cfg.num_observational_train_samples = 30\n",
    "env_cfg.num_observational_test_samples = 20\n",
    "env_cfg.generate_static_intr_dataset = True\n",
    "env_cfg.num_train_interventions = 5\n",
    "env_cfg.num_interventional_train_samples = 10\n",
    "env_cfg.num_test_interventions = 1\n",
    "env_cfg.num_interventional_test_samples = 10\n",
    "env_cfg.normalise_data = False\n",
    "env = ErdosRenyi(num_nodes=5, cfg=env_cfg)\n",
    "\n",
    "# plot true graph\n",
    "nx.draw(env.graph, nx.circular_layout(env.graph), labels=dict(zip(env.graph.nodes, env.graph.nodes)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Now we export the observational and interventional data as .csv files to some test directory. You can explore the generated .csv files to see the data format.",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "testdir = '../test/'\n",
    "os.makedirs(testdir, exist_ok=True)\n",
    "env.export_to_csv(testdir)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "The following we use the previously exported data to illustrate how to load a static dataset. In the simples case, we only load the graph and observational training data.",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "graph = graph_from_csv(os.path.join(testdir, f'{env.name}-adj-mat.csv'))\n",
    "obs_train = pd.read_csv(os.path.join(testdir, f'{env.name}-obs-train.csv'))\n",
    "\n",
    "loaded_env = Environment.load_static_dataset(graph, obs_train)\n",
    "print(loaded_env.get_adj_mat())\n",
    "print(loaded_env.observational_train_data[0].interventions)\n",
    "print(loaded_env.observational_train_data[0].num_batches)\n",
    "print(loaded_env.observational_train_data[0].batch_size)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also load observational test data and interventional data like so. It's also possible to only load interventional (training) data, etc."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "graph = graph_from_csv(os.path.join(testdir, f'{env.name}-adj-mat.csv'))\n",
    "obs_train = pd.read_csv(os.path.join(testdir, f'{env.name}-obs-train.csv'))\n",
    "obs_test = pd.read_csv(os.path.join(testdir, f'{env.name}-obs-test.csv'))\n",
    "\n",
    "intr_train = [pd.read_csv(os.path.join(testdir, f'{env.name}-intr-train-1.csv')),\n",
    "              pd.read_csv(os.path.join(testdir, f'{env.name}-intr-train-2.csv'))]\n",
    "\n",
    "intr_test = [pd.read_csv(os.path.join(testdir, f'{env.name}-intr-test-1.csv')),\n",
    "             pd.read_csv(os.path.join(testdir, f'{env.name}-intr-test-2.csv'))]\n",
    "\n",
    "loaded_env = Environment.load_static_dataset(graph, obs_train, obs_test, intr_train, intr_test, normalise=False)\n",
    "\n",
    "print(loaded_env.interventional_train_data[0].interventions)\n",
    "print(loaded_env.interventional_train_data[0].num_batches)\n",
    "print(loaded_env.interventional_train_data[0].batch_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, it's also possible to normalise the data to zero mean and unit variance by using the `normalise` option. The normalisation constants are computed from the observational training data in this case."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "graph = graph_from_csv(os.path.join(testdir, f'{env.name}-adj-mat.csv'))\n",
    "obs_train = pd.read_csv(os.path.join(testdir, f'{env.name}-obs-train.csv'))\n",
    "\n",
    "intr_train = [pd.read_csv(os.path.join(testdir, f'{env.name}-intr-train-1.csv')),\n",
    "              pd.read_csv(os.path.join(testdir, f'{env.name}-intr-train-2.csv'))]\n",
    "\n",
    "loaded_env = Environment.load_static_dataset(graph, obs_train, intr_train_data=intr_train, normalise=True)\n",
    "\n",
    "print(loaded_env.interventional_train_data[0].interventions)\n",
    "print(loaded_env.interventional_train_data[0].num_batches)\n",
    "print(loaded_env.interventional_train_data[0].batch_size)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
